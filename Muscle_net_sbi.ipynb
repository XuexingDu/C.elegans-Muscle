{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spirit/anaconda3/envs/sbi_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import brainpy as bp\n",
    "import brainpy.math as bm\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"  # specify which GPU(s) to be used\n",
    "bm.disable_gpu_memory_preallocation()\n",
    "bm.set_platform('gpu')\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sbi.inference import (\n",
    "    likelihood_estimator_based_potential,\n",
    "    SNLE,\n",
    "    prepare_for_sbi,\n",
    "    simulate_for_sbi,\n",
    "    VIPosterior,\n",
    ")\n",
    "\n",
    "from scipy import sparse\n",
    "# sbi\n",
    "from sbi.inference import SNPE, SNRE, SNLE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.utils.get_nn_models import posterior_nn, likelihood_nn, classifier_nn\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from scipy.stats import kurtosis as kurt\n",
    "from sbi.utils.user_input_checks import process_pytorch_prior, process_simulator\n",
    "\n",
    "# # sbi\n",
    "# from sbi import utils as utils\n",
    "# from sbi import analysis as analysis\n",
    "# from sbi.inference.base import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Body_Wall_muscle(bp.NeuGroup):\n",
    "    def __init__(self, size, ECa= 60., gCa= 15.6, EK=-40., gK=34., EL=-24, gL=0.1,\n",
    "                 V_th= 10., C= 22, p_max = 0.1, phi=1., phi_m = 1.2, gkr = 10., g_slo2 = 10. , g_Na = 0.01, ENa = 30, phi_n = 1.2, noise_factor = 0.01, **kwargs):\n",
    "        # providing the group \"size\" information\n",
    "        super(Body_Wall_muscle, self).__init__(size=size, **kwargs)\n",
    "\n",
    "        # initialize parameters\n",
    "        self.ECa = ECa\n",
    "        self.EK = EK\n",
    "        self.EL = EL\n",
    "        self.ENa = ENa\n",
    "        self.gCa = gCa\n",
    "        self.g_Na   = g_Na\n",
    "        self.gK = gK\n",
    "        self.gL = gL\n",
    "        self.C = C\n",
    "        self.p_max = p_max\n",
    "        self.V_th  = V_th\n",
    "        self.noise =  noise_factor \n",
    "        self.phi_m  = phi_m\n",
    "        self.phi_n  = phi_n\n",
    "        self.alpha  = 43.\n",
    "        self.beta   = 0.09\n",
    "        self.g_slo2 = g_slo2\n",
    "        self.gkr    = gkr\n",
    "        self.phi    = phi\n",
    "\n",
    "        # initialize variables\n",
    "        self.V = bm.Variable(bm.random.randn(self.num) - 30.)\n",
    "        self.m = bm.Variable(0.01 * bm.ones(self.num))\n",
    "        self.h = bm.Variable(0.6 * bm.ones(self.num))\n",
    "        self.n = bm.Variable(0.99 * bm.ones(self.num))\n",
    "        self.p = bm.Variable(0.2 * bm.ones(self.num))\n",
    "        self.kr = bm.Variable(0.0 * bm.ones(self.num))\n",
    "\n",
    "        self.p_slo2 = bm.Variable(bm.zeros(self.num))\n",
    "        self.Ca   = bm.Variable(bm.zeros(self.num))\n",
    "        self.Ica  = bm.Variable(bm.zeros(self.num))\n",
    "\n",
    "        self.input = bm.Variable(bm.zeros(self.num))\n",
    "        self.spike = bm.Variable(bm.zeros(self.num, dtype=bool))\n",
    "        self.t_last_spike = bm.Variable(bm.ones(self.num) * -1e7)\n",
    "\n",
    "        # integral functions\n",
    "        self.int_V = bp.odeint(f=self.dV, method='exp_auto')\n",
    "        self.int_m = bp.odeint(f=self.dm, method='exp_auto')\n",
    "        self.int_h = bp.odeint(f=self.dh, method='exp_auto')\n",
    "        self.int_n = bp.odeint(f=self.dn, method='exp_auto')\n",
    "        self.int_p = bp.odeint(f=self.dp, method='exp_auto')\n",
    "        self.int_p_slo2 = bp.odeint(f=self.dp_slo2, method='exp_auto')\n",
    "        self.int_Ca = bp.odeint(f=self.dCa, method='exp_auto')\n",
    "        self.int_kr = bp.odeint(f=self.dkr, method='exp_auto')\n",
    "\n",
    "    def dV(self, V, t, m, h, n, p, p_slo2, kr, Iext):\n",
    "        I_Ca = (self.gCa * m ** 2.0 * h) * (V - self.V_th - self.ECa)\n",
    "        I_K = (self.gK * n ** 4.0) * (V - self.V_th - self.EK)\n",
    "        I_M = (self.p_max * p) * (V - self.V_th - self.EK)\n",
    "        I_slo2 = (self.g_slo2 * self.m_slo2inf(V)**3 * p_slo2) * (V -  self.EK)\n",
    "        I_Na = self.g_Na * (V - self.V_th - self.ENa)\n",
    "        I_kr = self.gkr *(1-kr) * self.krinf(V) *  (V - self.EK)\n",
    "        I_leak = self.gL * (V - self.V_th  - self.EL)\n",
    "        dVdt = (- I_Ca  - I_K - I_Na - I_slo2 - I_leak - I_kr - I_M + Iext) / self.C\n",
    "        return dVdt\n",
    "    \n",
    "    krinf  = lambda self, V: 0.5 *(1+bm.tanh((V -  self.V_th + 42)/ 5.0))\n",
    "    m_slo2inf = lambda self, V: 1/(1+bm.exp(-(V - (-33.4)) / 3.2))\n",
    "\n",
    "    def dkr(self, kr, t, V):\n",
    "        # krinf = 0.5 *(1+bm.tanh((V -  self.V_th + 42)/ 5.0))\n",
    "        taumkr= 62\n",
    "        dkrdt = (self.krinf(V)-kr)/taumkr\n",
    "        return dkrdt\n",
    "\n",
    "    def dp_slo2(self, p_slo2, t, Ca, V):\n",
    "        C2 = self.alpha * bm.power(Ca, 2)\n",
    "        C3 = C2 + self.beta\n",
    "        return self.phi * (C2 / C3 - p_slo2) * C3\n",
    "\n",
    "    def dCa(self, Ca, t, m, h, V):\n",
    "        ICa = (self.gCa * m ** 2.0 * h) * (V - self.V_th - self.ECa)\n",
    "        return -0.15 * ICa * 1e-4 - 0.075 * (Ca - 0.001)\n",
    "\n",
    "    def dn(self, n, t, V):\n",
    "        ninf = 0.5 * (bm.tanh((V - self.V_th +15.2)/36.22)+1)\n",
    "        tau_n = 1.18+511.78/(1+bm.exp((V - self.V_th + 89.3)/21.92))\n",
    "        dndt = self.phi_n * (ninf-n)/tau_n\n",
    "        return dndt\n",
    "\n",
    "    # def dm(self, m, t, V):\n",
    "    #     tau_m = 61/(1+bm.exp((V - self.V_th + 81.2)/45.6)) + 22.39/(1+bm.exp(-(V - self.V_th -24.26)/22.26)) - 14.25 \n",
    "    #     minf = -0.53/(1+bm.exp(-(V - self.V_th - 26)/6.4)) + 1.058/(1+bm.exp(-(V - self.V_th +8.75)/7.2655)) + 0.0095\n",
    "    #     dmdt = self.phi_m * (minf-m)/tau_m\n",
    "    #     return dmdt\n",
    "\n",
    "    def dm(self, m, t, V):\n",
    "        tau_m = 0.4 + .7 / (bm.exp(-(V + 5. - self.V_th) / 15.) +\n",
    "                       bm.exp((V + 5. - self.V_th) / 15.))\n",
    "        minf = 1. / (1 + bm.exp(-(V + 8. - self.V_th) / 8.6))\n",
    "        dmdt = self.phi_m * (minf-m)/tau_m\n",
    "        return dmdt\n",
    "\n",
    "    def dh(self, h, t, V):\n",
    "        # hinf = 0.435/(1+bm.exp((V  - self.V_th + 10.38)/0.5554)) + 64.045/(1+bm.exp(-(V  - self.V_th -171.5)/30.8)) + 0.1\n",
    "        hinf   = 0.42 / (1. + bm.exp((V + 11. - self.V_th) / 2.)) + 0.28\n",
    "        # hinf  = (1.43 / (1 + bm.exp(-(V - self.V_th + 15 - 14.9) / 12)) + 0.14) * (5.96 / (1 + bm.exp((V  - self.V_th  + 15 + 20.5) / 8.1)) + 0.6 - 0.32)\n",
    "        tau_h = 24\n",
    "        dhdt = (hinf-h)/tau_h\n",
    "        return dhdt\n",
    "\n",
    "    def dp(self, p, t, V):\n",
    "        pinf = 1/(1+bm.exp(-(V- self.V_th +45)/10))\n",
    "        tau_p = 4000/(3.38*bm.exp((V- self.V_th+45)/20)+bm.exp(-(V- self.V_th +45)/20))\n",
    "        dpdt = (pinf-p)/tau_p\n",
    "        return dpdt\n",
    "\n",
    "    def update(self, tdi, x=None):\n",
    "        _t, _dt = tdi.t, tdi.dt\n",
    "        # compute V, m, h, n\n",
    "        noise_add = self.noise * bm.random.randn(self.num) / bm.sqrt(_dt)\n",
    "        V = self.int_V(self.V, _t, self.m, self.h, self.n, self.p, self.p_slo2, self.kr, self.input/0.75, dt=_dt)\n",
    "        self.h.value = self.int_h(self.h, _t, self.V, dt=_dt)\n",
    "        self.m.value = self.int_m(self.m, _t, self.V, dt=_dt)\n",
    "        self.n.value = self.int_n(self.n, _t, self.V, dt=_dt)\n",
    "        self.p.value = self.int_p(self.p, _t, self.V, dt=_dt)\n",
    "        self.p_slo2.value = self.int_p_slo2(self.p_slo2, _t, self.Ca, self.V, dt=_dt)\n",
    "        self.Ca.value = self.int_Ca(self.Ca, _t, self.m, self.h, self.V, dt=_dt)\n",
    "        self.kr.value = self.int_kr(self.kr, _t, self.V, dt=_dt)\n",
    "        self.Ica.value = (self.gCa * self.m ** 2.0 * self.h) * (self.V - self.V_th - self.ECa)\n",
    "\n",
    "        # update the spiking state and the last spiking time\n",
    "        self.spike.value = bm.logical_and(self.V < self.V_th, V >= self.V_th)\n",
    "        self.t_last_spike.value = bm.where(self.spike, _t, self.t_last_spike)\n",
    "\n",
    "        # update V\n",
    "        self.V.value = V\n",
    "\n",
    "        # reset the external input\n",
    "        self.input[:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neuron_connection_matrix(A):\n",
    "    \"\"\"\n",
    "    生成神经元连接矩阵，其中组内连接强度由矩阵 A 控制。\n",
    "    \n",
    "    参数:\n",
    "    A: 控制每组内连接强度的矩阵，维度为 [n, group_size-1]，n 是组的数量，group_size 是每组内神经元的数量 + 1（A 的列数 + 1）。\n",
    "    \n",
    "    返回:\n",
    "    稀疏的神经元连接矩阵\n",
    "    \"\"\"\n",
    "    num_groups = A.shape[0]\n",
    "    group_size = A.shape[1] + 1  # A的列数 + 1 是组内神经元数量\n",
    "\n",
    "    # 构建每个组的组内连接矩阵\n",
    "    group_connections = [\n",
    "        sparse.diags([A[i, :], A[i, :]], [-1, 1], shape=(group_size, group_size))\n",
    "        for i in range(num_groups)\n",
    "    ]\n",
    "    \n",
    "    # 使用稀疏矩阵的 block_diag 函数将每个组的连接矩阵沿对角线拼接\n",
    "    connection_matrix = sparse.block_diag(group_connections, format='csr')\n",
    "    \n",
    "    return connection_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([\n",
    "#     [0.5, 0.3, 0.7],\n",
    "#     [0.6, 0.2, 0.8]\n",
    "# ])\n",
    "# matrix = generate_neuron_connection_matrix(A)\n",
    "# print(matrix)\n",
    "# conn = bp.conn.SparseMatConn(matrix)\n",
    "# print(conn.value)\n",
    "# data = matrix.data\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\tTrue\n",
      "  (0, 1)\tTrue\n",
      "  (0, 2)\tTrue\n",
      "  (1, 2)\tTrue\n",
      "  (2, 2)\tTrue\n",
      "  (3, 0)\tTrue\n",
      "  (3, 1)\tTrue\n",
      "  (4, 0)\tTrue\n",
      "  (4, 2)\tTrue\n"
     ]
    }
   ],
   "source": [
    "conn_mat = np.random.randint(2, size=(5, 3), dtype=bp.math.bool_)\n",
    "sparse_mat = csr_matrix(conn_mat)\n",
    "print(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration  = 1000.\n",
    "small_size = 6\n",
    "groups     = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuscleNet(bp.DynamicalSystemNS):\n",
    "    def __init__(self , conn_matrix, net_size, **kwargs):\n",
    "        super().__init__()\n",
    "        g_max = conn_matrix.data\n",
    "        self.N = Body_Wall_muscle(size= net_size)\n",
    "        # self.N2N = bp.synapses.GapJunction(pre = self.N, post = self.N, conn = bp.connect.All2All(), g_max = conn_matrix)\n",
    "        self.N2N = bp.synapses.GapJunction(pre = self.N, post = self.N, conn = bp.conn.SparseMatConn(conn_matrix), comp_method ='sparse' ,g_max = g_max)\n",
    "        \n",
    "    def update(self):\n",
    "        t = bp.share.load('t')\n",
    "        dt = bp.share.load('dt')\n",
    "        self.N()\n",
    "        self.N2N() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([\n",
    "#     [0.5, 0.3, 0.7],\n",
    "#     [0.6, 0.2, 0.8]\n",
    "# ])\n",
    "# connection_matrix = generate_neuron_connection_matrix(A)\n",
    "# net_size = A.shape[0] * (A.shape[1] + 1)\n",
    "\n",
    "# conn = bp.conn.SparseMatConn(connection_matrix)\n",
    "# mat = conn.require(\"conn_mat\")\n",
    "# print(mat)\n",
    "# muscle_net = MuscleNet(connection_matrix, net_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Net_model(params):\n",
    "    params   = bm.asarray(params)\n",
    "    net_size = params.shape[0] *(params.shape[1] + 1)\n",
    "    connection_matrix = generate_neuron_connection_matrix(params)\n",
    "    # w_real = bm.array(connection_matrix)\n",
    "    net = MuscleNet(\n",
    "        conn_matrix =  connection_matrix, net_size = net_size\n",
    "    )    \n",
    "    runner = bp.DSRunner(\n",
    "        net, \n",
    "        monitors=['N.spike', 'N.V'], \n",
    "        inputs= ['N.input', bm.tile(bm.linspace(30, 0, 6), params.shape[0])],  \n",
    "        progress_bar=False\n",
    "    )\n",
    "    runner.run(duration)\n",
    "    return dict(t=runner.mon['ts'], spikes=runner.mon['N.spike'].T, data=runner.mon['N.V'].T, dt = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_first_spike = lambda x: np.where(x)[0][0] if np.any(x) else 0\n",
    "def compute_mean_isi(neuron_spikes):\n",
    "    spike_times = np.where(neuron_spikes)[0]\n",
    "    if len(spike_times) > 1:\n",
    "        intervals = np.diff(spike_times)\n",
    "        return np.mean(intervals)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def calculate_summary_statistics(x):\n",
    "    v =  np.array(x[\"data\"])\n",
    "    t = x[\"t\"]\n",
    "    dt = x[\"dt\"]\n",
    "    # Mean and standard deviation during stimulation\n",
    "    v_stim = v\n",
    "    mean_v_stim = np.mean(v_stim, axis=1)\n",
    "    std_v_stim  = np.std(v_stim, axis=1)\n",
    "    max_v_stim  = np.max(v_stim, axis=1) / 10.0\n",
    "\n",
    "    # spike calculation\n",
    "    spike_counts = x['spikes'].sum(axis=1)\n",
    "    mean_isi_values = np.apply_along_axis(compute_mean_isi, axis=1, arr=x['spikes']) * dt\n",
    "    first_spike_times = np.apply_along_axis(time_to_first_spike, axis=1, arr=x['spikes']) * dt\n",
    "\n",
    "    sum_stats_vec = np.column_stack((\n",
    "        spike_counts,\n",
    "        mean_isi_values/20.,\n",
    "        first_spike_times/20.,\n",
    "        mean_v_stim,\n",
    "        std_v_stim,\n",
    "        max_v_stim\n",
    "    ))\n",
    "    sum_stats_vec_mean = sum_stats_vec.reshape(-1, small_size, sum_stats_vec.shape[1]).mean(axis=1)\n",
    "    return sum_stats_vec_mean\n",
    "\n",
    "def simulation_wrapper(params):\n",
    "    \"\"\"\n",
    "    Returns summary statistics from conductance values in `params`.\n",
    "    Summarizes the output of the simulation and converts it to `torch.Tensor`.\n",
    "    \"\"\"\n",
    "    obs = run_Net_model(params)\n",
    "    summstats = torch.as_tensor(calculate_summary_statistics(obs))\n",
    "    return summstats.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_min = [5. , 5.,  10., 8.,  5.]\n",
    "# prior_max = [20.,  20.0, 18., 16., 14.,]\n",
    "# prior_min = [10. , 10.,  10., 8.,  5.]\n",
    "# prior_max = [20.,  20.0, 16., 15., 15.,]\n",
    "\n",
    "prior_min = [10. , 10.,  10., 8.,  5.]\n",
    "prior_max = [25.,  23.0, 18., 15., 15.,]\n",
    "\n",
    "# prior_min = [10.5 , 20.,   1e-4]\n",
    "# prior_max = [50.0, 55.0,   30.,]\n",
    "prior = utils.torchutils.BoxUniform(low=torch.as_tensor(prior_min),\n",
    "                                        high=torch.as_tensor(prior_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true_params = np.array([[15., 14., 13., 12.,11.]])\n",
    "true_params = np.array([[20., 17., 15., 11., 9.]])\n",
    "# true_params = np.array([[19.8, 37., 22., 10., 10.]])\n",
    "# true_params = np.array([[15.6, 34., 10.]])\n",
    "true_params.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate samples from the prior distribution\n",
    "num_rounds = 3\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "# real_group = 1\n",
    "# conn_real_matrix = generate_neuron_connection_matrix(n_groups= real_group , group_size=small_size)\n",
    "# w_real = bm.array(conn_real_matrix)\n",
    "\n",
    "true_data = run_Net_model(true_params)\n",
    "xo = calculate_summary_statistics(true_data)\n",
    "# xo = torch.tensor(xo, dtype=torch.float32)\n",
    "# x_aike =[[5.       ,  103.625   ,    70.2    ,    -29.00938034  , 0.21364328,\n",
    "#   -11.58708191 , 17.44003296  , 3.21818399  , 3.58649588]]\n",
    "xo = torch.tensor(xo, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  4.0000,   5.0561,  34.1375, -25.1901,  10.7755,   3.0057]])\n"
     ]
    }
   ],
   "source": [
    "print(xo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10000)\n",
      "torch.Size([1, 6])\n",
      "done.\n",
      " Neural network successfully converged after 158 epochs.Training inference network... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 30.84Std: 0.06:  40%|███▉      | 790/2000 [00:15<00:24, 49.60it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converged with loss: 30.84\n",
      "Quality Score: 0.264 \t Good: Smaller than 0.5  Bad: Larger than 1.0 \t         NOTE: Less sensitive to mode collapse.\n",
      "done.\n",
      " Neural network successfully converged after 127 epochs.Training inference network... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 33.59Std: 0.2:  24%|██▎       | 473/2000 [00:09<00:32, 47.56it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converged with loss: 33.59\n",
      "Quality Score: 0.181 \t Good: Smaller than 0.5  Bad: Larger than 1.0 \t         NOTE: Less sensitive to mode collapse.\n",
      "done.\n",
      " Neural network successfully converged after 33 epochs.Training inference network... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 32.34Std: 0.13:  72%|███████▏  | 1445/2000 [00:29<00:11, 49.14it/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converged with loss: 32.34\n",
      "Quality Score: 0.282 \t Good: Smaller than 0.5  Bad: Larger than 1.0 \t         NOTE: Less sensitive to mode collapse.\n"
     ]
    }
   ],
   "source": [
    "print(true_data['data'].shape)\n",
    "print(xo.shape)\n",
    "\n",
    "inference = SNLE(prior)\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((8_000,))\n",
    "    stats = simulation_wrapper(theta)\n",
    "    print('done.')\n",
    "    likelihood_estimator = inference.append_simulations(\n",
    "        theta, stats,\n",
    "    ).train()\n",
    "    print('Training inference network... ')\n",
    "    potential_fn, theta_transform = likelihood_estimator_based_potential(\n",
    "        likelihood_estimator, prior, xo\n",
    "    )\n",
    "    posterior = VIPosterior(\n",
    "        potential_fn, prior, \"maf\", theta_transform, vi_method=\"fKL\",\n",
    "    ).train()\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('Muscle_Net.npz', samples=samples, true_params=true_params, true_data=true_data, xo=xo)\n",
    "samples = posterior.sample((3000,), x=xo, show_progress_bars=False)\n",
    "np.savez('data/Muscle_Net_4.npz', samples=samples, true_params=true_params, true_data=true_data, xo=xo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
